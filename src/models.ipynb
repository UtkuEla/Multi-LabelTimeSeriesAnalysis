{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, LSTM, Dropout, concatenate, GlobalMaxPooling1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesModel:\n",
    "    \"\"\"\n",
    "    This class inolves different model architectures\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def Parallel_CNN_RNN(self):\n",
    "        \n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        conv_layer1 = Conv1D(filters=32, kernel_size=3, activation='relu')(input_layer)\n",
    "        conv_layer2 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv_layer1)\n",
    "        conv_layer3 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv_layer2)\n",
    "        maxpool_layer = MaxPooling1D(pool_size=2)(conv_layer3)\n",
    "        rnn_layer = LSTM(units=64, return_sequences=True)(maxpool_layer)\n",
    "        cnn_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(maxpool_layer)\n",
    "        cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "        cnn_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_layer)\n",
    "        cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "        cnn_layer = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_layer)\n",
    "        cnn_layer = MaxPooling1D(pool_size=2)(cnn_layer)\n",
    "        cnn_layer = Flatten()(cnn_layer)\n",
    "        combined_layer = concatenate([rnn_layer, cnn_layer])\n",
    "        global_pooling_layer = GlobalMaxPooling1D()(combined_layer)\n",
    "        dense_layer = Dense(units=128, activation='relu')(global_pooling_layer)\n",
    "        dropout_layer = Dropout(0.5)(dense_layer)\n",
    "        output_layer = Dense(units=self.num_classes, activation='softmax')(dropout_layer)\n",
    "        \n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        return model\n",
    "\n",
    "    def CNN_RNN_1(self):\n",
    "        \n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        conv_layer1 = Conv1D(filters=64, kernel_size=5, activation='relu')(input_layer)\n",
    "        conv_layer2 = Conv1D(filters=64, kernel_size=5, activation='relu')(conv_layer1)\n",
    "        maxpool_layer = MaxPooling1D(pool_size=2)(conv_layer2)\n",
    "        rnn_layer = LSTM(units=128, return_sequences=True)(maxpool_layer)\n",
    "        rnn_layer = LSTM(units=128)(rnn_layer)\n",
    "        dense_layer = Dense(units=256, activation='relu')(rnn_layer)\n",
    "        output_layer = Dense(units=self.num_classes, activation='softmax')(dense_layer)\n",
    "        \n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def CNN_RNN_2(self):\n",
    "        \n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        conv_layer1 = Conv1D(filters=32, kernel_size=3, activation='relu')(input_layer)\n",
    "        conv_layer2 = Conv1D(filters=32, kernel_size=3, activation='relu')(conv_layer1)\n",
    "        maxpool_layer = MaxPooling1D(pool_size=2)(conv_layer2)\n",
    "        rnn_layer = LSTM(units=64, return_sequences=True)(maxpool_layer)\n",
    "        rnn_layer = LSTM(units=64)(rnn_layer)\n",
    "        dense_layer = Dense(units=128, activation='relu')(rnn_layer)\n",
    "        output_layer = Dense(units=self.num_classes, activation='softmax')(dense_layer)\n",
    "        \n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "        return model\n",
    "\n",
    "    def EchoStateSimple(self):\n",
    "        input_layer = Input(shape=self.input_shape)\n",
    "        rnn_layer = SimpleRNN(units=self.num_units, activation='relu')(input_layer)\n",
    "        dense_layer = Dense(units=self.num_units, activation='relu')(rnn_layer)\n",
    "        output_layer = Dense(units=self.input_shape[1])(dense_layer)\n",
    "\n",
    "        model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def RNN_SLP_fromWeb(self):\n",
    "        \n",
    "    #     # Define timesteps and the number of features\n",
    "\n",
    "    #     n_timesteps = 8\n",
    "\n",
    "    #     n_features = 7\n",
    "\n",
    "    #     # RNN + SLP Model\n",
    "\n",
    "    #     # Define input layer\n",
    "\n",
    "    #     recurrent_input = Input(shape=(n_timesteps,n_features),name=&amp;amp;amp;quot;TIMESERIES_INPUT&amp;amp;amp;quot;)\n",
    "\n",
    "    #     static_input = Input(shape=(x_train_over_static.shape[1], ),name=&amp;amp;amp;quot;STATIC_INPUT&amp;amp;amp;quot;)\n",
    "\n",
    "    #     # RNN Layers\n",
    "\n",
    "    #     # layer - 1\n",
    "\n",
    "    #     rec_layer_one = Bidirectional(LSTM(128, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01),return_sequences=True),name =&amp;amp;amp;quot;BIDIRECTIONAL_LAYER_1&amp;amp;amp;quot;)(recurrent_input)\n",
    "\n",
    "    #     rec_layer_one = Dropout(0.1,name =&amp;amp;amp;quot;DROPOUT_LAYER_1&amp;amp;amp;quot;)(rec_layer_one)\n",
    "\n",
    "    #     # layer - 2\n",
    "\n",
    "    #     rec_layer_two = Bidirectional(LSTM(64, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01)),name =&amp;amp;amp;quot;BIDIRECTIONAL_LAYER_2&amp;amp;amp;quot;)(rec_layer_one)\n",
    "\n",
    "    #     rec_layer_two = Dropout(0.1,name =&amp;amp;amp;quot;DROPOUT_LAYER_2&amp;amp;amp;quot;)(rec_layer_two)\n",
    "\n",
    "    #     # SLP Layers\n",
    "\n",
    "    #     static_layer_one = Dense(64, kernel_regularizer=l2(0.001), activation='relu',name=&amp;amp;amp;quot;DENSE_LAYER_1&amp;amp;amp;quot;)(static_input)\n",
    "\n",
    "    #     # Combine layers - RNN + SLP\n",
    "\n",
    "    #     combined = Concatenate(axis= 1,name = &amp;amp;amp;quot;CONCATENATED_TIMESERIES_STATIC&amp;amp;amp;quot;)([rec_layer_two,static_layer_one])\n",
    "\n",
    "    #     combined_dense_two = Dense(64, activation='relu',name=&amp;amp;amp;quot;DENSE_LAYER_2&amp;amp;amp;quot;)(combined)\n",
    "\n",
    "    #     output = Dense(n_outputs,activation='sigmoid',name=&amp;amp;amp;quot;OUTPUT_LAYER&amp;amp;amp;quot;)(combined_dense_two)\n",
    "\n",
    "    #     # Compile Model\n",
    "\n",
    "    #     model = Model(inputs=[recurrent_input,static_input],outputs=[output])\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "InceptionTime\n",
    "\n",
    "https://github.com/hfawaz/InceptionTime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet model\n",
    "import keras\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils.utils import save_logs\n",
    "from utils.utils import calculate_metrics\n",
    "from utils.utils import save_test_duration\n",
    "\n",
    "\n",
    "class Classifier_INCEPTION:\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, batch_size=64,\n",
    "                 nb_filters=32, use_residual=True, use_bottleneck=True, depth=6, kernel_size=41, nb_epochs=1500):\n",
    "\n",
    "        self.output_directory = output_directory\n",
    "\n",
    "        self.nb_filters = nb_filters\n",
    "        self.use_residual = use_residual\n",
    "        self.use_bottleneck = use_bottleneck\n",
    "        self.depth = depth\n",
    "        self.kernel_size = kernel_size - 1\n",
    "        self.callbacks = None\n",
    "        self.batch_size = batch_size\n",
    "        self.bottleneck_size = 32\n",
    "        self.nb_epochs = nb_epochs\n",
    "\n",
    "        if build == True:\n",
    "            self.model = self.build_model(input_shape, nb_classes)\n",
    "            if (verbose == True):\n",
    "                self.model.summary()\n",
    "            self.verbose = verbose\n",
    "            self.model.save_weights(self.output_directory + 'model_init.hdf5')\n",
    "\n",
    "    def _inception_module(self, input_tensor, stride=1, activation='linear'):\n",
    "\n",
    "        if self.use_bottleneck and int(input_tensor.shape[-1]) > 1:\n",
    "            input_inception = keras.layers.Conv1D(filters=self.bottleneck_size, kernel_size=1,\n",
    "                                                  padding='same', activation=activation, use_bias=False)(input_tensor)\n",
    "        else:\n",
    "            input_inception = input_tensor\n",
    "\n",
    "        # kernel_size_s = [3, 5, 8, 11, 17]\n",
    "        kernel_size_s = [self.kernel_size // (2 ** i) for i in range(3)]\n",
    "\n",
    "        conv_list = []\n",
    "\n",
    "        for i in range(len(kernel_size_s)):\n",
    "            conv_list.append(keras.layers.Conv1D(filters=self.nb_filters, kernel_size=kernel_size_s[i],\n",
    "                                                 strides=stride, padding='same', activation=activation, use_bias=False)(\n",
    "                input_inception))\n",
    "\n",
    "        max_pool_1 = keras.layers.MaxPool1D(pool_size=3, strides=stride, padding='same')(input_tensor)\n",
    "\n",
    "        conv_6 = keras.layers.Conv1D(filters=self.nb_filters, kernel_size=1,\n",
    "                                     padding='same', activation=activation, use_bias=False)(max_pool_1)\n",
    "\n",
    "        conv_list.append(conv_6)\n",
    "\n",
    "        x = keras.layers.Concatenate(axis=2)(conv_list)\n",
    "        x = keras.layers.BatchNormalization()(x)\n",
    "        x = keras.layers.Activation(activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    def _shortcut_layer(self, input_tensor, out_tensor):\n",
    "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
    "                                         padding='same', use_bias=False)(input_tensor)\n",
    "        shortcut_y = keras.layers.normalization.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        x = keras.layers.Add()([shortcut_y, out_tensor])\n",
    "        x = keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self, input_shape, nb_classes):\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        x = input_layer\n",
    "        input_res = input_layer\n",
    "\n",
    "        for d in range(self.depth):\n",
    "\n",
    "            x = self._inception_module(x)\n",
    "\n",
    "            if self.use_residual and d % 3 == 2:\n",
    "                x = self._shortcut_layer(input_res, x)\n",
    "                input_res = x\n",
    "\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50,\n",
    "                                                      min_lr=0.0001)\n",
    "\n",
    "        file_path = self.output_directory + 'best_model.hdf5'\n",
    "\n",
    "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
    "                                                           save_best_only=True)\n",
    "\n",
    "        self.callbacks = [reduce_lr, model_checkpoint]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, x_train, y_train, x_val, y_val, y_true, plot_test_acc=False):\n",
    "        if len(keras.backend.tensorflow_backend._get_available_gpus()) == 0:\n",
    "            print('error no gpu')\n",
    "            exit()\n",
    "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
    "\n",
    "        if self.batch_size is None:\n",
    "            mini_batch_size = int(min(x_train.shape[0] / 10, 16))\n",
    "        else:\n",
    "            mini_batch_size = self.batch_size\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if plot_test_acc:\n",
    "\n",
    "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
    "                                  verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks)\n",
    "        else:\n",
    "\n",
    "            hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=self.nb_epochs,\n",
    "                                  verbose=self.verbose, callbacks=self.callbacks)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        self.model.save(self.output_directory + 'last_model.hdf5')\n",
    "\n",
    "        y_pred = self.predict(x_val, y_true, x_train, y_train, y_val,\n",
    "                              return_df_metrics=False)\n",
    "\n",
    "        # save predictions\n",
    "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
    "\n",
    "        # convert the predicted from binary to integer\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        df_metrics = save_logs(self.output_directory, hist, y_pred, y_true, duration,\n",
    "                               plot_test_acc=plot_test_acc)\n",
    "\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        return df_metrics\n",
    "\n",
    "    def predict(self, x_test, y_true, x_train, y_train, y_test, return_df_metrics=True):\n",
    "        start_time = time.time()\n",
    "        model_path = self.output_directory + 'best_model.hdf5'\n",
    "        model = keras.models.load_model(model_path)\n",
    "        y_pred = model.predict(x_test, batch_size=self.batch_size)\n",
    "        if return_df_metrics:\n",
    "            y_pred = np.argmax(y_pred, axis=1)\n",
    "            df_metrics = calculate_metrics(y_true, y_pred, 0.0)\n",
    "            return df_metrics\n",
    "        else:\n",
    "            test_duration = time.time() - start_time\n",
    "            save_test_duration(self.output_directory + 'test_duration.csv', test_duration)\n",
    "            return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from utils.utils import calculate_metrics\n",
    "from utils.utils import create_directory\n",
    "from utils.utils import check_if_file_exits\n",
    "import gc\n",
    "from utils.constants import UNIVARIATE_ARCHIVE_NAMES  as ARCHIVE_NAMES\n",
    "import time\n",
    "\n",
    "\n",
    "class Classifier_NNE:\n",
    "\n",
    "    def create_classifier(self, model_name, input_shape, nb_classes, output_directory, verbose=False,\n",
    "                          build=True):\n",
    "        if self.check_if_match('inception*', model_name):\n",
    "            from classifiers import inception\n",
    "            return inception.Classifier_INCEPTION(output_directory, input_shape, nb_classes, verbose,\n",
    "                                                  build=build)\n",
    "\n",
    "    def check_if_match(self, rex, name2):\n",
    "        import re\n",
    "        pattern = re.compile(rex)\n",
    "        return pattern.match(name2)\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, nb_iterations=5,\n",
    "                 clf_name='inception'):\n",
    "        self.classifiers = [clf_name]\n",
    "        out_add = ''\n",
    "        for cc in self.classifiers:\n",
    "            out_add = out_add + cc + '-'\n",
    "        self.archive_name = ARCHIVE_NAMES[0]\n",
    "        self.iterations_to_take = [i for i in range(nb_iterations)]\n",
    "        for cc in self.iterations_to_take:\n",
    "            out_add = out_add + str(cc) + '-'\n",
    "        self.output_directory = output_directory.replace('nne',\n",
    "                                                         'nne' + '/' + out_add)\n",
    "        create_directory(self.output_directory)\n",
    "        self.dataset_name = output_directory.split('/')[-2]\n",
    "        self.verbose = verbose\n",
    "        self.models_dir = output_directory.replace('nne', 'classifier')\n",
    "\n",
    "    def fit(self, x_train, y_train, x_test, y_test, y_true):\n",
    "        # no training since models are pre-trained\n",
    "        start_time = time.time()\n",
    "\n",
    "        y_pred = np.zeros(shape=y_test.shape)\n",
    "\n",
    "        ll = 0\n",
    "\n",
    "        # loop through all classifiers\n",
    "        for model_name in self.classifiers:\n",
    "            # loop through different initialization of classifiers\n",
    "            for itr in self.iterations_to_take:\n",
    "                if itr == 0:\n",
    "                    itr_str = ''\n",
    "                else:\n",
    "                    itr_str = '_itr_' + str(itr)\n",
    "\n",
    "                curr_archive_name = self.archive_name + itr_str\n",
    "\n",
    "                curr_dir = self.models_dir.replace('classifier', model_name).replace(\n",
    "                    self.archive_name, curr_archive_name)\n",
    "\n",
    "                model = self.create_classifier(model_name, None, None,\n",
    "                                               curr_dir, build=False)\n",
    "\n",
    "                predictions_file_name = curr_dir + 'y_pred.npy'\n",
    "                # check if predictions already made\n",
    "                if check_if_file_exits(predictions_file_name):\n",
    "                    # then load only the predictions from the file\n",
    "                    curr_y_pred = np.load(predictions_file_name)\n",
    "                else:\n",
    "                    # then compute the predictions\n",
    "                    curr_y_pred = model.predict(x_test, y_true, x_train, y_train, y_test,\n",
    "                                                return_df_metrics=False)\n",
    "                    keras.backend.clear_session()\n",
    "\n",
    "                    np.save(predictions_file_name, curr_y_pred)\n",
    "\n",
    "                y_pred = y_pred + curr_y_pred\n",
    "\n",
    "                ll += 1\n",
    "\n",
    "        # average predictions\n",
    "        y_pred = y_pred / ll\n",
    "\n",
    "        # save predictions\n",
    "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
    "\n",
    "        # convert the predicted from binary to integer\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        df_metrics = calculate_metrics(y_true, y_pred, duration)\n",
    "\n",
    "        df_metrics.to_csv(self.output_directory + 'df_metrics.csv', index=False)\n",
    "\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
